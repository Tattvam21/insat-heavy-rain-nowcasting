{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c81942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "\n",
    "std_path = \"../DATASET/RAW/STD\"\n",
    "files = os.listdir(std_path)\n",
    "\n",
    "print(\"Total STD files:\", len(files))\n",
    "print(\"Sample file:\", files[0])\n",
    "\n",
    "file_path = os.path.join(std_path, files[0])\n",
    "\n",
    "with h5py.File(file_path, \"r\") as f:\n",
    "    print(\"Keys in STD file:\")\n",
    "    for key in f.keys():\n",
    "        print(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657af2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hem_path = \"../DATASET/RAW/HEM\"\n",
    "files = os.listdir(hem_path)\n",
    "\n",
    "print(\"Total HEM files:\", len(files))\n",
    "print(\"Sample file:\", files[0])\n",
    "\n",
    "file_path = os.path.join(hem_path, files[0])\n",
    "\n",
    "with h5py.File(file_path, \"r\") as f:\n",
    "    print(\"Keys in HEM file:\")\n",
    "    for key in f.keys():\n",
    "        print(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acc2139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 1ï¸âƒ£ Define paths relative to NOTEBOOKS folder\n",
    "# --------------------------------------------------\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "\n",
    "STD_DIR = PROJECT_ROOT / \"DATASET\" / \"RAW\" / \"STD\"\n",
    "HEM_DIR = PROJECT_ROOT / \"DATASET\" / \"RAW\" / \"HEM\"\n",
    "MATCHED_FILE = PROJECT_ROOT / \"DATASET\" / \"PROCESSED\" / \"matched_files.pkl\"\n",
    "\n",
    "print(\"Project Root:\", PROJECT_ROOT)\n",
    "print(\"STD Path:\", STD_DIR)\n",
    "print(\"HEM Path:\", HEM_DIR)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 2ï¸âƒ£ Load matched file list\n",
    "# --------------------------------------------------\n",
    "with open(MATCHED_FILE, \"rb\") as f:\n",
    "    matched_data = pickle.load(f)\n",
    "\n",
    "print(\"Total matched samples:\", len(matched_data))\n",
    "\n",
    "# Take first sample\n",
    "sample = matched_data[0]\n",
    "\n",
    "std_path = STD_DIR / sample[\"std_file\"]\n",
    "hem_path = HEM_DIR / sample[\"hem_file\"]\n",
    "\n",
    "print(\"STD file:\", std_path)\n",
    "print(\"HEM file:\", hem_path)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 3ï¸âƒ£ Inspect STD file\n",
    "# --------------------------------------------------\n",
    "with h5py.File(std_path, \"r\") as f:\n",
    "    print(\"\\nSTD Keys:\")\n",
    "    print(list(f.keys()))\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 4ï¸âƒ£ Inspect HEM file\n",
    "# --------------------------------------------------\n",
    "with h5py.File(hem_path, \"r\") as f:\n",
    "    print(\"\\nHEM Keys:\")\n",
    "    print(list(f.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5041bcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "with h5py.File(std_path, \"r\") as f:\n",
    "    tir1 = f[\"TIR1_BT\"][:]\n",
    "    tir2 = f[\"TIR2_BT\"][:]\n",
    "    wv   = f[\"WV_BT\"][:]\n",
    "\n",
    "print(\"TIR1 shape:\", tir1.shape, \"min:\", np.min(tir1), \"max:\", np.max(tir1))\n",
    "print(\"TIR2 shape:\", tir2.shape, \"min:\", np.min(tir2), \"max:\", np.max(tir2))\n",
    "print(\"WV shape:\", wv.shape, \"min:\", np.min(wv), \"max:\", np.max(wv))\n",
    "\n",
    "with h5py.File(hem_path, \"r\") as f:\n",
    "    hem = f[\"HEM\"][:]\n",
    "\n",
    "print(\"HEM shape:\", hem.shape, \"min:\", np.min(hem), \"max:\", np.max(hem))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854f0363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Remove extra dimension\n",
    "tir1 = tir1[0]\n",
    "tir2 = tir2[0]\n",
    "wv   = wv[0]\n",
    "hem  = hem[0]\n",
    "\n",
    "print(\"After squeeze:\")\n",
    "print(\"TIR1:\", tir1.shape)\n",
    "print(\"WV:\", wv.shape)\n",
    "print(\"HEM:\", hem.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddf6648",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_resized = cv2.resize(\n",
    "    wv,\n",
    "    (tir1.shape[1], tir1.shape[0]),\n",
    "    interpolation=cv2.INTER_LINEAR\n",
    ")\n",
    "\n",
    "print(\"WV resized shape:\", wv_resized.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e8d369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_bt(x):\n",
    "    return (x - 180) / (320 - 180)\n",
    "\n",
    "tir1 = normalize_bt(tir1)\n",
    "tir2 = normalize_bt(tir2)\n",
    "wv_resized = normalize_bt(wv_resized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8d25dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (512, 512)\n",
    "\n",
    "X_resized = np.stack([\n",
    "    cv2.resize(X[i], target_size, interpolation=cv2.INTER_LINEAR)\n",
    "    for i in range(3)\n",
    "])\n",
    "\n",
    "Y_resized = cv2.resize(Y, target_size, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "print(\"Downsampled X:\", X_resized.shape)\n",
    "print(\"Downsampled Y:\", Y_resized.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e733db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "\n",
    "Y = np.load(PROJECT_ROOT / \"DATASET/PROCESSED/Y_event.npy\")\n",
    "\n",
    "Y_t = Y[:-1]\n",
    "Y_t1 = Y[1:]\n",
    "\n",
    "same = np.sum(Y_t == Y_t1)\n",
    "total = len(Y_t)\n",
    "\n",
    "print(\"Persistence rate:\", same / total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055675a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from pathlib import Path\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "\n",
    "Y = np.load(PROJECT_ROOT / \"DATASET/PROCESSED/Y_event.npy\")\n",
    "\n",
    "Y_t = Y[:-1]\n",
    "Y_t1 = Y[1:]\n",
    "\n",
    "acc = accuracy_score(Y_t1, Y_t)\n",
    "f1 = f1_score(Y_t1, Y_t)\n",
    "\n",
    "print(\"Persistence Accuracy:\", acc)\n",
    "print(\"Persistence F1:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28eb76a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "\n",
    "Y = np.load(PROJECT_ROOT / \"DATASET/PROCESSED/Y_event.npy\")\n",
    "\n",
    "lead = 3\n",
    "Y_t = Y[:-lead]\n",
    "Y_t3 = Y[lead:]\n",
    "\n",
    "acc = accuracy_score(Y_t3, Y_t)\n",
    "f1 = f1_score(Y_t3, Y_t)\n",
    "\n",
    "print(\"Persistence t+3 Accuracy:\", acc)\n",
    "print(\"Persistence t+3 F1:\", f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70b1365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "\n",
    "Y = np.load(PROJECT_ROOT / \"DATASET/PROCESSED/Y_event.npy\")\n",
    "\n",
    "lead = 6\n",
    "\n",
    "Y_t = Y[:-lead]\n",
    "Y_t6 = Y[lead:]\n",
    "\n",
    "acc = accuracy_score(Y_t6, Y_t)\n",
    "f1 = f1_score(Y_t6, Y_t)\n",
    "\n",
    "print(\"Persistence t+6 Accuracy:\", acc)\n",
    "print(\"Persistence t+6 F1:\", f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113e34fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "\n",
    "Y = np.load(PROJECT_ROOT / \"DATASET/PROCESSED/Y_event.npy\")\n",
    "\n",
    "history = 3\n",
    "lead = 6\n",
    "\n",
    "start_idx = history - 1\n",
    "end_idx = len(Y) - lead\n",
    "\n",
    "Y_t6 = Y[start_idx+lead : end_idx+lead]\n",
    "\n",
    "print(\"Validation rain ratio:\",\n",
    "      np.mean(Y_t6[int(0.7*len(Y_t6)) : int(0.85*len(Y_t6))]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c8eb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "\n",
    "Y_onset = np.load(PROJECT_ROOT / \"DATASET/PROCESSED/Y_onset_t3.npy\")\n",
    "\n",
    "Y_pred = np.zeros_like(Y_onset)\n",
    "\n",
    "acc = accuracy_score(Y_onset, Y_pred)\n",
    "f1 = f1_score(Y_onset, Y_pred)\n",
    "\n",
    "print(\"Persistence (always no-onset)\")\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"F1:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9b01bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "Y = np.load(PROJECT_ROOT / \"DATASET/PROCESSED/Y_onset_t3.npy\")\n",
    "start = 3-1\n",
    "n = len(Y)\n",
    "train_end = int(0.7*n); val_end=int(0.85*n)\n",
    "print(np.mean(Y[:train_end]), np.mean(Y[train_end:val_end]), np.mean(Y[val_end:]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dfa490",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Manually set project root\n",
    "PROJECT_ROOT = Path(\"/Users/apple/Documents/ElteBook/Code/PROJECT/XAI NEW\")\n",
    "\n",
    "with open(PROJECT_ROOT / \"DATASET/PROCESSED/matched_files.pkl\", \"rb\") as f:\n",
    "    matched_files = pickle.load(f)\n",
    "\n",
    "print(\"Type of matched_files:\", type(matched_files))\n",
    "print(\"Type of first element:\", type(matched_files[0]))\n",
    "print(\"First element:\")\n",
    "print(matched_files[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f83976",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(\"/Users/apple/Documents/ElteBook/Code/PROJECT/XAI NEW\")\n",
    "\n",
    "HEM = np.load(PROJECT_ROOT / \"DATASET/PROCESSED/HEM_256.npy\")\n",
    "\n",
    "print(\"Min:\", HEM.min())\n",
    "print(\"Max:\", HEM.max())\n",
    "print(\"Mean:\", HEM.mean())\n",
    "print(\"Percentiles:\", np.percentile(HEM, [50, 75, 90, 95, 99]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126e9f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(\"/Users/apple/Documents/ElteBook/Code/PROJECT/XAI NEW\")\n",
    "\n",
    "HEM = np.load(PROJECT_ROOT / \"DATASET/PROCESSED/HEM_256.npy\")\n",
    "\n",
    "thresholds = [0.2, 0.5, 1, 2, 5]\n",
    "\n",
    "for t in thresholds:\n",
    "    frame_positive = []\n",
    "    for frame in HEM:\n",
    "        coverage = np.mean(frame > t)\n",
    "        frame_positive.append(coverage > 0.005)\n",
    "\n",
    "    print(f\"Threshold {t} â†’ Event ratio: {np.mean(frame_positive)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32809805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(\"/Users/apple/Documents/ElteBook/Code/PROJECT/XAI NEW/DATASET/PROCESSED\")\n",
    "\n",
    "X = np.load(BASE / \"X_patch_event.npy\")\n",
    "Y = np.load(BASE / \"Y_patch_event.npy\")\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"Y shape:\", Y.shape)\n",
    "print(\"Event ratio:\", Y.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0feceaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "BASE = Path(\"/Users/apple/Documents/ElteBook/Code/PROJECT/XAI NEW/DATASET/PROCESSED\")\n",
    "\n",
    "X = np.load(BASE / \"X_patch_event.npy\")\n",
    "\n",
    "# choose one patch\n",
    "sample = X[100]  # change index if needed\n",
    "\n",
    "# convert to HWC format\n",
    "sample = np.transpose(sample, (1,2,0))\n",
    "\n",
    "# normalize to 0-255 for saving\n",
    "sample = (sample - sample.min()) / (sample.max() - sample.min())\n",
    "sample = (sample * 255).astype(np.uint8)\n",
    "\n",
    "img = Image.fromarray(sample)\n",
    "img.save(\"demo_patch.png\")\n",
    "\n",
    "print(\"Saved demo_patch.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcfb7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "# ðŸ”¹ Set your project root manually\n",
    "PROJECT_ROOT = Path(\"/Users/apple/Documents/ElteBook/Code/PROJECT/XAI NEW\")\n",
    "\n",
    "# ðŸ”¹ Load real patch dataset (the one used for training)\n",
    "X_patch = np.load(PROJECT_ROOT / \"DATASET/PROCESSED/X_patch_event.npy\")\n",
    "Y_patch = np.load(PROJECT_ROOT / \"DATASET/PROCESSED/Y_patch_event.npy\")\n",
    "\n",
    "print(\"Dataset shape:\", X_patch.shape)\n",
    "print(\"Event ratio:\", Y_patch.mean())\n",
    "\n",
    "# ðŸ”¹ Pick a TRUE POSITIVE patch\n",
    "positive_indices = np.where(Y_patch == 1)[0]\n",
    "idx = positive_indices[0]\n",
    "\n",
    "patch = X_patch[idx]  # (3, 64, 64)\n",
    "\n",
    "print(\"Selected index:\", idx)\n",
    "print(\"Patch shape:\", patch.shape)\n",
    "\n",
    "# ðŸ”¹ Convert to displayable image (for frontend demo only)\n",
    "patch_vis = np.transpose(patch, (1, 2, 0))  # (64,64,3)\n",
    "\n",
    "# Normalize for visualization\n",
    "patch_vis = patch_vis - patch_vis.min()\n",
    "patch_vis = patch_vis / (patch_vis.max() + 1e-6)\n",
    "\n",
    "patch_vis_uint8 = (patch_vis * 255).astype(np.uint8)\n",
    "\n",
    "# ðŸ”¹ Save PNG for frontend testing\n",
    "save_path = PROJECT_ROOT / \"NOTEBOOK/demo_patch.png\"\n",
    "Image.fromarray(patch_vis_uint8).save(save_path)\n",
    "\n",
    "print(\"âœ… Demo patch saved at:\", save_path)\n",
    "\n",
    "# ðŸ”¹ Show inline\n",
    "plt.imshow(patch_vis_uint8)\n",
    "plt.title(\"Real Training Patch\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02ff7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "# Update this path if needed\n",
    "PROJECT_ROOT = Path(\"/Users/apple/Documents/ElteBook/Code/PROJECT/XAI NEW\")\n",
    "\n",
    "# Load dataset\n",
    "X = np.load(PROJECT_ROOT / \"DATASET/PROCESSED/X_patch_event.npy\")\n",
    "Y = np.load(PROJECT_ROOT / \"DATASET/PROCESSED/Y_patch_event.npy\")\n",
    "\n",
    "print(\"Dataset shape:\", X.shape)\n",
    "print(\"Event ratio:\", Y.mean())\n",
    "\n",
    "# ðŸ”¥ Find first heavy rain patch\n",
    "heavy_indices = np.where(Y == 1)[0]\n",
    "idx = heavy_indices[0]\n",
    "\n",
    "print(\"Selected heavy index:\", idx)\n",
    "\n",
    "patch = X[idx]  # shape (3, 64, 64)\n",
    "\n",
    "# Convert to displayable image\n",
    "patch_img = np.transpose(patch, (1, 2, 0))  # CHW -> HWC\n",
    "\n",
    "# Normalize for visualization\n",
    "patch_img = (patch_img - patch_img.min()) / (patch_img.max() - patch_img.min() + 1e-8)\n",
    "\n",
    "# Save PNG\n",
    "save_path = PROJECT_ROOT / \"NOTEBOOKs/heavy_demo.png\"\n",
    "save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "Image.fromarray((patch_img * 255).astype(np.uint8)).save(save_path)\n",
    "\n",
    "print(\"âœ… Heavy rain patch saved at:\", save_path)\n",
    "\n",
    "# Show it\n",
    "plt.imshow(patch_img)\n",
    "plt.title(\"Heavy Rain Patch\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ae7043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "PROJECT_ROOT = Path(\"/Users/apple/Documents/ElteBook/Code/PROJECT/XAI NEW\")\n",
    "\n",
    "X = np.load(PROJECT_ROOT / \"DATASET/PROCESSED/X_patch_event.npy\")\n",
    "Y = np.load(PROJECT_ROOT / \"DATASET/PROCESSED/Y_patch_event.npy\")\n",
    "\n",
    "heavy_indices = np.where(Y == 1)[0]\n",
    "\n",
    "print(\"Total heavy patches:\", len(heavy_indices))\n",
    "\n",
    "# ðŸ”¥ Random heavy patch\n",
    "idx = random.choice(heavy_indices)\n",
    "\n",
    "patch = X[idx]\n",
    "\n",
    "img = patch.transpose(1,2,0)\n",
    "\n",
    "# Normalize for saving\n",
    "img_norm = img - img.min()\n",
    "img_norm = img_norm / (img_norm.max() + 1e-8)\n",
    "\n",
    "img_uint8 = (img_norm * 255).astype(np.uint8)\n",
    "\n",
    "filename = f\"heavy_demo_{idx}.png\"\n",
    "plt.imsave(filename, img_uint8)\n",
    "\n",
    "plt.imshow(img_uint8)\n",
    "plt.title(f\"Heavy Patch Index {idx}\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "print(\"Saved:\", filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2a1b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path().resolve().parent\n",
    "\n",
    "X = np.load(PROJECT_ROOT / \"DATASET/PROCESSED/X_patch_multiframe_t3.npy\")\n",
    "Y = np.load(PROJECT_ROOT / \"DATASET/PROCESSED/Y_patch_multiframe_t3.npy\")\n",
    "\n",
    "idx = np.where(Y == 1)[0][0]\n",
    "\n",
    "sample = X[idx]\n",
    "\n",
    "np.save(PROJECT_ROOT / \"NOTEBOOKs/heavy_sample.npy\", sample)\n",
    "\n",
    "print(\"Saved heavy_sample.npy at:\", PROJECT_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a329c835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (49104, 9, 64, 64)\n",
      "Event ratio: 0.22896301726946888\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "PROJECT_ROOT = Path().resolve().parent\n",
    "\n",
    "X = np.load(PROJECT_ROOT / \"DATASET/PROCESSED/X_patch_multiframe_t3.npy\")\n",
    "Y = np.load(PROJECT_ROOT / \"DATASET/PROCESSED/Y_patch_multiframe_t3.npy\")\n",
    "\n",
    "print(\"Dataset shape:\", X.shape)\n",
    "print(\"Event ratio:\", Y.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c24642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_samples(class_value, count=3):\n",
    "    indices = np.where(Y == class_value)[0]\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    selected = indices[:count]\n",
    "\n",
    "    for i, idx in enumerate(selected):\n",
    "        sample = X[idx]\n",
    "\n",
    "        # Save .npy file\n",
    "        np.save(PROJECT_ROOT / f\"sample_{class_value}_{i}.npy\", sample)\n",
    "\n",
    "        # Save PNG preview (first 3 channels only)\n",
    "        img = sample[:3]  # first time frame\n",
    "        img = np.transpose(img, (1,2,0))\n",
    "\n",
    "        # normalize for visualization\n",
    "        img = (img - img.min()) / (img.max() - img.min() + 1e-8)\n",
    "\n",
    "    print(f\"Saved {count} samples for class {class_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a7088e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 3 samples for class 1\n",
      "Saved 3 samples for class 0\n"
     ]
    }
   ],
   "source": [
    "# Heavy Rain samples\n",
    "save_samples(class_value=1, count=3)\n",
    "\n",
    "# No Heavy Rain samples\n",
    "save_samples(class_value=0, count=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd43820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PROJECT_ROOT = Path().resolve().parent\n",
    "\n",
    "X = np.load(PROJECT_ROOT / \"DATASET/PROCESSED/X_patch_multiframe_t3.npy\")\n",
    "Y = np.load(PROJECT_ROOT / \"DATASET/PROCESSED/Y_patch_multiframe_t3.npy\")\n",
    "\n",
    "print(\"Dataset shape:\", X.shape)\n",
    "print(\"Event ratio:\", Y.mean())\n",
    "\n",
    "\n",
    "def save_samples(class_value, count=5):\n",
    "    indices = np.where(Y == class_value)[0]\n",
    "    \n",
    "    if len(indices) < count:\n",
    "        print(f\"Not enough samples for class {class_value}\")\n",
    "        return\n",
    "    \n",
    "    np.random.shuffle(indices)\n",
    "    selected = indices[:count]\n",
    "\n",
    "    for i, idx in enumerate(selected):\n",
    "        sample = X[idx]\n",
    "\n",
    "        # ðŸ”¹ Save .npy file\n",
    "        np.save(PROJECT_ROOT / f\"sample_class{class_value}_{i}.npy\", sample)\n",
    "\n",
    "        # ðŸ”¹ Save PNG preview (first time frame only)\n",
    "        img = sample[:3]  # first time step (3 channels)\n",
    "        img = np.transpose(img, (1, 2, 0))\n",
    "\n",
    "        # normalize for visualization\n",
    "        img = (img - img.min()) / (img.max() - img.min() + 1e-8)\n",
    "\n",
    "        plt.imsave(PROJECT_ROOT / f\"sample_class{class_value}_{i}.png\", img)\n",
    "\n",
    "    print(f\"Saved {count} samples for class {class_value}\")\n",
    "\n",
    "\n",
    "# âœ… 5 Heavy Rain samples\n",
    "save_samples(class_value=1, count=5)\n",
    "\n",
    "# âœ… 5 No Heavy Rain samples\n",
    "save_samples(class_value=0, count=5)\n",
    "\n",
    "print(\"âœ… Total 10 samples saved successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
